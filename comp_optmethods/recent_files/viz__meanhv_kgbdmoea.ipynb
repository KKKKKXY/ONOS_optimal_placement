{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8743046d-b869-4bf8-9c76-303a2ccfcd02",
   "metadata": {},
   "source": [
    "# Visualize pymoo result\n",
    "Load the pymoo result object saved with pickle and visualize it.\n",
    "\n",
    "ONOSControllerPlacement needs to be definded to load the result object.\n",
    "So, execute the following cell first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddb40093-adb5-4fcd-8aee-56971de76e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import math\n",
    "import pickle\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "\n",
    "class ONOSControllerPlacement(ElementwiseProblem):\n",
    "    def __init__(self, num_nodes, distance_matrix, shortest_paths, graph, **kwargs):\n",
    "        super().__init__(n_var=2*num_nodes, \n",
    "                         n_obj=4, \n",
    "                         n_constr=2, \n",
    "                         xl=0, xu=1, \n",
    "                         **kwargs)\n",
    "        self.num_nodes = num_nodes\n",
    "        self.distance_matrix = distance_matrix\n",
    "        self.shortest_paths = shortest_paths\n",
    "        self.graph = graph\n",
    "    \n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        controller_nodes = x[:self.num_nodes]   # first half is controller placement\n",
    "        atomix_nodes = x[self.num_nodes:]       # second half is atomix placement\n",
    "\n",
    "\n",
    "        num_controller = np.sum(controller_nodes)\n",
    "        num_atomix = np.sum(atomix_nodes)\n",
    "\n",
    "        # Obj1: Minimize number of contrtoller\n",
    "        f1 = num_controller\n",
    "\n",
    "        # Obj2: Minimize number of atomix\n",
    "        f2 = num_atomix\n",
    "\n",
    "        # Obj3: Minimize average FSP\n",
    "        f3 = calculate_FST(self.num_nodes, \n",
    "                           controller_nodes, \n",
    "                           atomix_nodes, \n",
    "                           self.distance_matrix, \n",
    "                           self.shortest_paths)\n",
    "        \n",
    "        f4 = calculate_BC(self.num_nodes, \n",
    "                           controller_nodes, \n",
    "                           atomix_nodes, \n",
    "                           self.distance_matrix, \n",
    "                        #    self.shortest_paths,\n",
    "                           self.graph)\n",
    "\n",
    "        # Constr1: The number of controller is equal to or greater than 2\n",
    "        g1 = 2 - num_controller\n",
    "\n",
    "        # Constr2: The number of atomix is equal to or greater than 3\n",
    "        g2 = 3 - num_atomix\n",
    "        \n",
    "        # Add the centrality metrix into optimazing objectives:\n",
    "        # 1. Nearest controller for each switch\n",
    "        # 2. The number of controlled switches for each controller should be <= limit_num_switches_controlled (limit_num_switches_controlled=int(math.ceil(num_nodes/num_controller)))\n",
    "        # 3. return value should be the variance for all controller's betweenness centrality\n",
    "        out[\"F\"] = [f1, f2, f3, f4]\n",
    "        out[\"G\"] = [g1, g2]\n",
    "\n",
    "\n",
    "def calculate_FST(num_nodes, controller_nodes, atomix_nodes, distance_matrix, shortest_paths):\n",
    "    num_controller = np.sum(controller_nodes)\n",
    "    num_atomix = np.sum(atomix_nodes)\n",
    "    controller_list = np.nonzero(controller_nodes)[0].tolist()\n",
    "    atomix_list = np.nonzero(atomix_nodes)[0].tolist()\n",
    "\n",
    "    if(num_controller == 0 or num_atomix ==0):\n",
    "        return math.inf\n",
    "\n",
    "    # find the nearest controller for each switch\n",
    "    controller_of = []\n",
    "    for s in range(num_nodes):\n",
    "        delay = math.inf\n",
    "        nearest_controller = None\n",
    "        for c in controller_list:\n",
    "            if distance_matrix[s][c] < delay:\n",
    "                delay = distance_matrix[s][c]\n",
    "                nearest_controller = c\n",
    "        controller_of.append(nearest_controller)    \n",
    "\n",
    "    # calculate average delay to atomix nodes from each controller\n",
    "    average_atomix_delay_from = {}\n",
    "    for c in controller_list:\n",
    "        delay = []\n",
    "        for a in atomix_list:\n",
    "            delay.append(distance_matrix[c][a])\n",
    "        average_atomix_delay_from[c] = np.mean(delay)\n",
    "\n",
    "    # find the nearest atomix for each atomix and calculate average delay\n",
    "    atomix_atomix_delays = []\n",
    "    for a1 in atomix_list:\n",
    "        delay = math.inf\n",
    "        for a2 in atomix_list:\n",
    "            if(a1 == a2):\n",
    "                continue\n",
    "            if distance_matrix[a1][a2] < delay:\n",
    "                delay = distance_matrix[a1][a2]\n",
    "        atomix_atomix_delays.append(delay)\n",
    "    average_atomix_atomix_delay = np.mean(atomix_atomix_delays)\n",
    "    FTSs = []\n",
    "    for source in range(num_nodes):\n",
    "        for distination in range(num_nodes):\n",
    "            if(source == distination):\n",
    "                continue\n",
    "            delay = 0\n",
    "            is_controlled_by_single_controller = True\n",
    "            counted_controllers = []\n",
    "            for s in shortest_paths[source][distination]:\n",
    "                # switch-controller delay\n",
    "                delay += distance_matrix[s][controller_of[s]] * 4\n",
    "\n",
    "                # controller-atomix delay\n",
    "                if(s == source):\n",
    "                    delay += average_atomix_delay_from[controller_of[s]] * 2\n",
    "                elif(s != distination):\n",
    "                    if(controller_of[s] != controller_of[source]):\n",
    "                        is_controlled_by_single_controller = False\n",
    "                        if(not controller_of[s] in counted_controllers):\n",
    "                            counted_controllers.append(controller_of[s])\n",
    "                            delay += average_atomix_delay_from[controller_of[s]]\n",
    "                else:\n",
    "                    if(controller_of[s] == controller_of[source]):\n",
    "                        if(not is_controlled_by_single_controller):\n",
    "                            delay += average_atomix_delay_from[controller_of[s]]\n",
    "                    else:\n",
    "                        delay += average_atomix_delay_from[controller_of[s]] * 2\n",
    "            \n",
    "            # atomix-atomix delay\n",
    "            delay +=  average_atomix_atomix_delay * 2\n",
    "            FTSs.append(delay)\n",
    "\n",
    "    return np.mean(FTSs)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_BC(num_nodes, controller_nodes, atomix_nodes, distance_matrix, graph):\n",
    "    G = nx.Graph()\n",
    "    for node1 in range(len(graph)):\n",
    "        G.add_node(str(node1))\n",
    "        for node2, delay in graph[node1].items():\n",
    "            G.add_edge(str(node1), str(node2), weight=delay)\n",
    "    \n",
    "    # The list of betweenness centrality for all switches\n",
    "    nodes_bc=nx.current_flow_betweenness_centrality(G, normalized=True, weight=None, dtype='float', solver='full')\n",
    "    num_controller = np.sum(controller_nodes)\n",
    "    num_atomix = np.sum(atomix_nodes)\n",
    "    controller_list = np.nonzero(controller_nodes)[0].tolist()\n",
    "\n",
    "    if(num_controller == 0 or num_atomix ==0):\n",
    "        return math.inf\n",
    "\n",
    "    # find the nearest controller for each switch\n",
    "    controller_of = []\n",
    "    limit_num_switches_controlled=int(math.ceil(num_nodes/num_controller)) # balance the number of switches controllers can control \n",
    "    switches_bc_of_controller_ = dict.fromkeys((range(num_nodes)),0) # list of sum of betweenness centrality of switches for each controller\n",
    "    for s in range(num_nodes):\n",
    "        delay = math.inf\n",
    "        nearest_controller = None\n",
    "        controlled_switches=[]\n",
    "        for c in controller_list:\n",
    "            # Conditions: nearest controller (with the lowest delay) && the number of switches for each controller < limit_num_switches_controlled\n",
    "            if distance_matrix[s][c] < delay and controller_of.count(c) < limit_num_switches_controlled:\n",
    "                delay = distance_matrix[s][c]\n",
    "                nearest_controller = c\n",
    "                controlled_switches.append(s)\n",
    "        switches_bc_of_controller_[nearest_controller] += nodes_bc[str(s)]\n",
    "        controller_of.append(nearest_controller)\n",
    "    \n",
    "    # Simplify switches_bc_of_controller_ (only need value for calculating variance)\n",
    "    bc_array = []\n",
    "    for i in switches_bc_of_controller_.values():\n",
    "        bc_array.append(i)\n",
    "\n",
    "    # return variance value can show the degree of balance within all controllers\n",
    "    return np.var(bc_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c5160c",
   "metadata": {},
   "source": [
    "### Load kgbdmoea results for all topos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116921fb-1d91-4612-9876-69374c2df104",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res_bc_Cogent_kgbdmoea.pkl','rb') as f_Cogent:\n",
    "    res_12_Cogent = pickle.load(f_Cogent)\n",
    "with open('res_bc_UsCarrier_kgbdmoea.pkl','rb') as f_UsCarrier:\n",
    "    res_12_UsCarrier = pickle.load(f_UsCarrier)\n",
    "with open('res_bc_HiberniaGlobal_kgbdmoea.pkl','rb') as f_HiberniaGlobal:\n",
    "    res_12_HiberniaGlobal = pickle.load(f_HiberniaGlobal)\n",
    "with open('res_bc_Colt_kgbdmoea.pkl','rb') as f_Colt:\n",
    "    res_12_Colt = pickle.load(f_Colt)\n",
    "with open('res_bc_Funet_kgbdmoea.pkl','rb') as f_Funet:\n",
    "    res_12_Funet = pickle.load(f_Funet)\n",
    "with open('res_bc_Abvt_kgbdmoea.pkl','rb') as f_Abvt:\n",
    "    res_12_Abvt = pickle.load(f_Abvt)\n",
    "with open('res_bc_Intellifiber_kgbdmoea.pkl','rb') as f_Intellifiber:\n",
    "    res_12_Intellifiber = pickle.load(f_Intellifiber)\n",
    "with open('res_bc_TataNld_kgbdmoea.pkl','rb') as f_TataNld:\n",
    "    res_12_TataNld = pickle.load(f_TataNld)\n",
    "with open('res_bc_Internode_kgbdmoea.pkl','rb') as f_Internode:\n",
    "    res_12_Internode = pickle.load(f_Internode)\n",
    "with open('res_bc_Missouri_kgbdmoea.pkl','rb') as f_Missouri:\n",
    "    res_12_Missouri = pickle.load(f_Missouri)\n",
    "with open('res_bc_Ion_kgbdmoea.pkl','rb') as f_Ion:\n",
    "    res_12_Ion = pickle.load(f_Ion)\n",
    "with open('res_bc_Palmetto_kgbdmoea.pkl','rb') as f_Palmetto:\n",
    "    res_12_Palmetto = pickle.load(f_Palmetto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4970f1-b0dd-4149-b53c-6369435edc08",
   "metadata": {},
   "source": [
    "## Hypervolume\n",
    "1. Store values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc125b3-deb4-44d5-a5e2-8f3a4837e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kgbdmoea\n",
    "F12_Cogent=res_12_Cogent.F\n",
    "F12_UsCarrier=res_12_UsCarrier.F\n",
    "F12_HiberniaGlobal=res_12_HiberniaGlobal.F\n",
    "F12_Colt=res_12_Colt.F\n",
    "F12_Funet=res_12_Funet.F\n",
    "F12_Abvt=res_12_Abvt.F\n",
    "F12_Intellifiber=res_12_Intellifiber.F\n",
    "F12_TataNld=res_12_TataNld.F\n",
    "F12_Internode=res_12_Internode.F\n",
    "F12_Missouri=res_12_Missouri.F\n",
    "F12_Ion=res_12_Ion.F\n",
    "F12_Palmetto=res_12_Palmetto.F\n",
    "\n",
    "# # Nadir Point from 9 Algorithms: \n",
    "# ref_point = [1.81000000e+02 6.20000000e+01 3.92281875e+03 1.70537209e+00]\n",
    "# # Nadir Point from 4 Algorithms: \n",
    "# ref_point = [160.  77.  inf  inf]\n",
    "# # Nadir Point from all (13) Algorithms: \n",
    "# ref_point = [181.  77.  inf  inf]\n",
    "\n",
    "ref_point = [181, 77, 3922.81875, 1.70537209]\n",
    "\n",
    "hist_F12_Cogent = []\n",
    "hist_F12_UsCarrier = []\n",
    "hist_F12_HiberniaGlobal = []\n",
    "hist_F12_Colt = []\n",
    "hist_F12_Funet = []\n",
    "hist_F12_Abvt = []\n",
    "hist_F12_Intellifiber = []\n",
    "hist_F12_TataNld = []\n",
    "hist_F12_Internode = []\n",
    "hist_F12_Missouri = []\n",
    "hist_F12_Ion = []\n",
    "hist_F12_Palmetto = []\n",
    "\n",
    "\n",
    "for algo12_Cogent in res_12_Cogent.history:\n",
    "    opt12_Cogent = algo12_Cogent.opt\n",
    "    feas12_Cogent = np.where(opt12_Cogent.get(\"feasible\"))[0]\n",
    "    hist_F12_Cogent.append(opt12_Cogent.get(\"F\")[feas12_Cogent])\n",
    "for algo12_UsCarrier in res_12_UsCarrier.history:\n",
    "    opt12_UsCarrier = algo12_UsCarrier.opt\n",
    "    feas12_UsCarrier = np.where(opt12_UsCarrier.get(\"feasible\"))[0]\n",
    "    hist_F12_UsCarrier.append(opt12_UsCarrier.get(\"F\")[feas12_UsCarrier])\n",
    "for algo12_HiberniaGlobal in res_12_HiberniaGlobal.history:\n",
    "    opt12_HiberniaGlobal = algo12_HiberniaGlobal.opt\n",
    "    feas12_HiberniaGlobal = np.where(opt12_HiberniaGlobal.get(\"feasible\"))[0]\n",
    "    hist_F12_HiberniaGlobal.append(opt12_HiberniaGlobal.get(\"F\")[feas12_HiberniaGlobal])\n",
    "for algo12_Colt in res_12_Colt.history:\n",
    "    opt12_Colt = algo12_Colt.opt\n",
    "    feas12_Colt = np.where(opt12_Colt.get(\"feasible\"))[0]\n",
    "    hist_F12_Colt.append(opt12_Colt.get(\"F\")[feas12_Colt])\n",
    "for algo12_Funet in res_12_Funet.history:\n",
    "    opt12_Funet = algo12_Funet.opt\n",
    "    feas12_Funet = np.where(opt12_Funet.get(\"feasible\"))[0]\n",
    "    hist_F12_Funet.append(opt12_Funet.get(\"F\")[feas12_Funet])\n",
    "for algo12_Abvt in res_12_Abvt.history:\n",
    "    opt12_Abvt = algo12_Abvt.opt\n",
    "    feas12_Abvt = np.where(opt12_Abvt.get(\"feasible\"))[0]\n",
    "    hist_F12_Abvt.append(opt12_Abvt.get(\"F\")[feas12_Abvt])\n",
    "for algo12_Intellifiber in res_12_Intellifiber.history:\n",
    "    opt12_Intellifiber = algo12_Intellifiber.opt\n",
    "    feas12_Intellifiber = np.where(opt12_Intellifiber.get(\"feasible\"))[0]\n",
    "    hist_F12_Intellifiber.append(opt12_Intellifiber.get(\"F\")[feas12_Intellifiber])\n",
    "for algo12_TataNld in res_12_TataNld.history:\n",
    "    opt12_TataNld = algo12_TataNld.opt\n",
    "    feas12_TataNld = np.where(opt12_TataNld.get(\"feasible\"))[0]\n",
    "    hist_F12_TataNld.append(opt12_TataNld.get(\"F\")[feas12_TataNld])\n",
    "for algo12_Internode in res_12_Internode.history:\n",
    "    opt12_Internode = algo12_Internode.opt\n",
    "    feas12_Internode= np.where(opt12_Internode.get(\"feasible\"))[0]\n",
    "    hist_F12_Internode.append(opt12_Internode.get(\"F\")[feas12_Internode])\n",
    "for algo12_Missouri in res_12_Missouri.history:\n",
    "    opt12_Missouri = algo12_Missouri.opt\n",
    "    feas12_Missouri = np.where(opt12_Missouri.get(\"feasible\"))[0]\n",
    "    hist_F12_Missouri.append(opt12_Missouri.get(\"F\")[feas12_Missouri])\n",
    "for algo12_Ion in res_12_Ion.history:\n",
    "    opt12_Ion = algo12_Ion.opt\n",
    "    feas12_Ion = np.where(opt12_Ion.get(\"feasible\"))[0]\n",
    "    hist_F12_Ion.append(opt12_Ion.get(\"F\")[feas12_Ion])\n",
    "for algo12_Palmetto in res_12_Palmetto.history:\n",
    "    opt12_Palmetto = algo12_Palmetto.opt\n",
    "    feas12_Palmetto = np.where(opt12_Palmetto.get(\"feasible\"))[0]\n",
    "    hist_F12_Palmetto.append(opt12_Palmetto.get(\"F\")[feas12_Palmetto])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bc35ce",
   "metadata": {},
   "source": [
    "2. Calculate hypervolume and merge them (Mean value) for kgbdmoea algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.indicators.hv import Hypervolume\n",
    "\n",
    "metric = Hypervolume(ref_point= np.array(ref_point))\n",
    "\n",
    "hv_12_Cogent = [metric.do(_F12_Cogent) for _F12_Cogent in hist_F12_Cogent]\n",
    "hv_12_UsCarrier = [metric.do(_F12_UsCarrier) for _F12_UsCarrier in hist_F12_UsCarrier]\n",
    "hv_12_HiberniaGlobal = [metric.do(_F12_HiberniaGlobal) for _F12_HiberniaGlobal in hist_F12_HiberniaGlobal]\n",
    "hv_12_Colt = [metric.do(_F12_Colt) for _F12_Colt in hist_F12_Colt]\n",
    "hv_12_Funet = [metric.do(_F12_Funet) for _F12_Funet in hist_F12_Funet]\n",
    "hv_12_Abvt = [metric.do(_F12_Abvt) for _F12_Abvt in hist_F12_Abvt]\n",
    "hv_12_Intellifiber = [metric.do(_F12_Intellifiber) for _F12_Intellifiber in hist_F12_Intellifiber]\n",
    "hv_12_TataNld = [metric.do(_F12_TataNld) for _F12_TataNld in hist_F12_TataNld]\n",
    "hv_12_Internode = [metric.do(_F12_Internode) for _F12_Internode in hist_F12_Internode]\n",
    "hv_12_Missouri = [metric.do(_F12_Missouri) for _F12_Missouri in hist_F12_Missouri]\n",
    "hv_12_Ion = [metric.do(_F12_Ion) for _F12_Ion in hist_F12_Ion]\n",
    "hv_12_Palmetto = [metric.do(_F12_Palmetto) for _F12_Palmetto in hist_F12_Palmetto]\n",
    "\n",
    "# kgbdmoea\n",
    "hv_12 = [(hv_Cogent + hv_UsCarrier + hv_HiberniaGlobal + hv_Colt + hv_Funet + hv_Abvt + hv_Intellifiber + hv_TataNld + hv_Internode + hv_Missouri + hv_Ion + hv_Palmetto) / 12 for hv_Cogent, hv_UsCarrier, hv_HiberniaGlobal, hv_Colt, hv_Funet, hv_Abvt, hv_Intellifiber, hv_TataNld, hv_Internode, hv_Missouri, hv_Ion, hv_Palmetto in zip(hv_12_Cogent, hv_12_UsCarrier, hv_12_HiberniaGlobal, hv_12_Colt, hv_12_Funet, hv_12_Abvt, hv_12_Intellifiber, hv_12_TataNld, hv_12_Internode, hv_12_Missouri, hv_12_Ion, hv_12_Palmetto)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff19c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The hypervolumn for Cogent:')\n",
    "print(hv_12_Cogent)\n",
    "print('The hypervolumn for UsCarrier:')\n",
    "print(hv_12_UsCarrier)\n",
    "print('The hypervolumn for HiberniaGlobal:')\n",
    "print(hv_12_HiberniaGlobal)\n",
    "print('The hypervolumn for Colt:')\n",
    "print(hv_12_Colt)\n",
    "print('The hypervolumn for Funet:')\n",
    "print(hv_12_Funet)\n",
    "print('The hypervolumn for Abvt:')\n",
    "print(hv_12_Abvt)\n",
    "print('The hypervolumn for Intellifiber:')\n",
    "print(hv_12_Intellifiber)\n",
    "print('The hypervolumn for TataNld:')\n",
    "print(hv_12_TataNld)\n",
    "print('The hypervolumn for Internode:')\n",
    "print(hv_12_Internode)\n",
    "print('The hypervolumn for Missouri:')\n",
    "print(hv_12_Missouri)\n",
    "print('The hypervolumn for Ion:')\n",
    "print(hv_12_Ion)\n",
    "print('The hypervolumn for Palmetto:')\n",
    "print(hv_12_Palmetto)\n",
    "\n",
    "# Show all hv for each topo\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(list(range(1, len(hv_12_Cogent)+1)), hv_12_Cogent,  color='black', label='Cogent')\n",
    "plt.plot(list(range(1, len(hv_12_UsCarrier)+1)), hv_12_UsCarrier,  color='blue', label='UsCarrier')\n",
    "plt.plot(list(range(1, len(hv_12_HiberniaGlobal)+1)), hv_12_HiberniaGlobal,  color='red', label='HiberniaGlobal')\n",
    "plt.plot(list(range(1, len(hv_12_Colt)+1)), hv_12_Colt,  color='orange', label='Colt')\n",
    "plt.plot(list(range(1, len(hv_12_Funet)+1)), hv_12_Funet,  color=(0, 0, 1, 0.5), label='Funet')\n",
    "plt.plot(list(range(1, len(hv_12_Abvt)+1)), hv_12_Abvt,  color='gray', label='Abvt')\n",
    "plt.plot(list(range(1, len(hv_12_Intellifiber)+1)), hv_12_Intellifiber,  color='purple', label='Intellifiber')\n",
    "plt.plot(list(range(1, len(hv_12_TataNld)+1)), hv_12_TataNld,  color='green', label='TataNld')\n",
    "plt.plot(list(range(1, len(hv_12_Internode)+1)), hv_12_Internode,  color='#33FF57', label='Internode')\n",
    "plt.plot(list(range(1, len(hv_12_Missouri)+1)), hv_12_Missouri,  color='brown', label='Missouri')\n",
    "plt.plot(list(range(1, len(hv_12_Ion)+1)), hv_12_Ion,  color='pink', label='Ion')\n",
    "plt.plot(list(range(1, len(hv_12_Palmetto)+1)), hv_12_Palmetto,  color='olive', label='Palmetto')\n",
    "plt.title(\"Convergence\")\n",
    "plt.xlabel(\"Topos\")\n",
    "plt.ylabel(\"Hypervolume\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e79067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The aveage of hypervolumn for kgbdmoea:')\n",
    "print(hv_12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a88ed",
   "metadata": {},
   "source": [
    "3. Draw mean hypervolume for kgbdmoea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e791203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#  Show all alogrithms' hv into a single figure\n",
    "plt.figure(figsize=(7, 5))\n",
    "# plt.plot(list(range(1, len(hv_1)+1)), hv_1,  color='black', label='AGEMOEA')\n",
    "# plt.plot(list(range(1, len(hv_2)+1)), hv_2,  color='blue', label='AGEMOEA2')\n",
    "# plt.plot(list(range(1, len(hv_3)+1)), hv_3,  color='red', label='NSGA2')\n",
    "# plt.plot(list(range(1, len(hv_4)+1)), hv_4,  color='orange', label='NSGA3')\n",
    "# plt.plot(list(range(1, len(hv_5)+1)), hv_5,  color=(0, 0, 1, 0.5), label='RNSGA2')\n",
    "# plt.plot(list(range(1, len(hv_6)+1)), hv_6,  color='gray', label='RNSGA3')\n",
    "# plt.plot(list(range(1, len(hv_7)+1)), hv_7,  color='purple', label='RVEA')\n",
    "# plt.plot(list(range(1, len(hv_8)+1)), hv_8,  color='green', label='SMSEMOA')\n",
    "# plt.plot(list(range(1, len(hv_9)+1)), hv_9,  color='#33FF57', label='UNSGA3')\n",
    "# plt.plot(list(range(1, len(hv_10)+1)), hv_10,  color='brown', label='CTAEA')\n",
    "# plt.plot(list(range(1, len(hv_11)+1)), hv_11,  color='pink', label='DNSGA2')\n",
    "plt.plot(list(range(1, len(hv_12)+1)), hv_12,  color='olive', label='KGBDMOEA')\n",
    "# plt.plot(list(range(1, len(hv_13)+1)), hv_13,  color='cyan', label='MOEAD')\n",
    "plt.title(\"Convergence\")\n",
    "plt.xlabel(\"Generations\") # brown,pink,#5733FF,olive,cyan,#FF5733,#33FF57\n",
    "plt.ylabel(\"Hypervolume\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
