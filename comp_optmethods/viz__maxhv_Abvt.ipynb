{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8c88b1f",
   "metadata": {},
   "source": [
    "# Visualize pymoo result\n",
    "Load the pymoo result object saved with pickle and visualize it.\n",
    "\n",
    "ONOSControllerPlacement needs to be definded to load the result object.\n",
    "So, execute the following cell first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9e065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import math\n",
    "import pickle\n",
    "from pymoo.core.problem import ElementwiseProblem\n",
    "\n",
    "class ONOSControllerPlacement(ElementwiseProblem):\n",
    "    def __init__(self, num_nodes, distance_matrix, shortest_paths, graph, **kwargs):\n",
    "        super().__init__(n_var=2*num_nodes, \n",
    "                         n_obj=4, \n",
    "                         n_constr=2, \n",
    "                         xl=0, xu=1, \n",
    "                         **kwargs)\n",
    "        self.num_nodes = num_nodes\n",
    "        self.distance_matrix = distance_matrix\n",
    "        self.shortest_paths = shortest_paths\n",
    "        self.graph = graph\n",
    "    \n",
    "    def _evaluate(self, x, out, *args, **kwargs):\n",
    "        controller_nodes = x[:self.num_nodes]   # first half is controller placement\n",
    "        atomix_nodes = x[self.num_nodes:]       # second half is atomix placement\n",
    "\n",
    "\n",
    "        num_controller = np.sum(controller_nodes)\n",
    "        num_atomix = np.sum(atomix_nodes)\n",
    "\n",
    "        # Obj1: Minimize number of contrtoller\n",
    "        f1 = num_controller\n",
    "\n",
    "        # Obj2: Minimize number of atomix\n",
    "        f2 = num_atomix\n",
    "\n",
    "        # Obj: Minimize average FSP\n",
    "        f3 = calculate_FST(self.num_nodes, \n",
    "                           controller_nodes, \n",
    "                           atomix_nodes, \n",
    "                           self.distance_matrix, \n",
    "                           self.shortest_paths)\n",
    "        \n",
    "        f4 = calculate_BC(self.num_nodes, \n",
    "                           controller_nodes, \n",
    "                           atomix_nodes, \n",
    "                           self.distance_matrix, \n",
    "                        #    self.shortest_paths,\n",
    "                           self.graph)\n",
    "\n",
    "        # Constr1: The number of controller is equal to or greater than 2\n",
    "        g1 = 2 - num_controller\n",
    "\n",
    "        # Constr2: The number of atomix is equal to or greater than 3\n",
    "        g2 = 3 - num_atomix\n",
    "        \n",
    "        # Add the centrality metrix into optimazing objectives:\n",
    "        # 1. Nearest controller for each switch\n",
    "        # 2. The number of controlled switches for each controller should be <= limit_num_switches_controlled (limit_num_switches_controlled=int(math.ceil(num_nodes/num_controller)))\n",
    "        # 3. return value should be the variance for all controller's betweenness centrality\n",
    "        out[\"F\"] = [f1, f2, f3, f4]\n",
    "        out[\"G\"] = [g1, g2]\n",
    "\n",
    "\n",
    "def calculate_FST(num_nodes, controller_nodes, atomix_nodes, distance_matrix, shortest_paths):\n",
    "    num_controller = np.sum(controller_nodes)\n",
    "    num_atomix = np.sum(atomix_nodes)\n",
    "    controller_list = np.nonzero(controller_nodes)[0].tolist()\n",
    "    atomix_list = np.nonzero(atomix_nodes)[0].tolist()\n",
    "\n",
    "    if(num_controller == 0 or num_atomix ==0):\n",
    "        return math.inf\n",
    "\n",
    "    # find the nearest controller for each switch\n",
    "    controller_of = []\n",
    "    for s in range(num_nodes):\n",
    "        delay = math.inf\n",
    "        nearest_controller = None\n",
    "        for c in controller_list:\n",
    "            if distance_matrix[s][c] < delay:\n",
    "                delay = distance_matrix[s][c]\n",
    "                nearest_controller = c\n",
    "        controller_of.append(nearest_controller)    \n",
    "\n",
    "    # calculate average delay to atomix nodes from each controller\n",
    "    average_atomix_delay_from = {}\n",
    "    for c in controller_list:\n",
    "        delay = []\n",
    "        for a in atomix_list:\n",
    "            delay.append(distance_matrix[c][a])\n",
    "        average_atomix_delay_from[c] = np.mean(delay)\n",
    "\n",
    "    # find the nearest atomix for each atomix and calculate average delay\n",
    "    atomix_atomix_delays = []\n",
    "    for a1 in atomix_list:\n",
    "        delay = math.inf\n",
    "        for a2 in atomix_list:\n",
    "            if(a1 == a2):\n",
    "                continue\n",
    "            if distance_matrix[a1][a2] < delay:\n",
    "                delay = distance_matrix[a1][a2]\n",
    "        atomix_atomix_delays.append(delay)\n",
    "    average_atomix_atomix_delay = np.mean(atomix_atomix_delays)\n",
    "    FTSs = []\n",
    "    for source in range(num_nodes):\n",
    "        for distination in range(num_nodes):\n",
    "            if(source == distination):\n",
    "                continue\n",
    "            delay = 0\n",
    "            is_controlled_by_single_controller = True\n",
    "            counted_controllers = []\n",
    "            for s in shortest_paths[source][distination]:\n",
    "                # switch-controller delay\n",
    "                delay += distance_matrix[s][controller_of[s]] * 4\n",
    "\n",
    "                # controller-atomix delay\n",
    "                if(s == source):\n",
    "                    delay += average_atomix_delay_from[controller_of[s]] * 2\n",
    "                elif(s != distination):\n",
    "                    if(controller_of[s] != controller_of[source]):\n",
    "                        is_controlled_by_single_controller = False\n",
    "                        if(not controller_of[s] in counted_controllers):\n",
    "                            counted_controllers.append(controller_of[s])\n",
    "                            delay += average_atomix_delay_from[controller_of[s]]\n",
    "                else:\n",
    "                    if(controller_of[s] == controller_of[source]):\n",
    "                        if(not is_controlled_by_single_controller):\n",
    "                            delay += average_atomix_delay_from[controller_of[s]]\n",
    "                    else:\n",
    "                        delay += average_atomix_delay_from[controller_of[s]] * 2\n",
    "            \n",
    "            # atomix-atomix delay\n",
    "            delay +=  average_atomix_atomix_delay * 2\n",
    "            FTSs.append(delay)\n",
    "\n",
    "    return np.mean(FTSs)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_BC(num_nodes, controller_nodes, atomix_nodes, distance_matrix, graph):\n",
    "    G = nx.Graph()\n",
    "    for node1 in range(len(graph)):\n",
    "        G.add_node(str(node1))\n",
    "        for node2, delay in graph[node1].items():\n",
    "            G.add_edge(str(node1), str(node2), weight=delay)\n",
    "    \n",
    "    # The list of betweenness centrality for all switches\n",
    "    nodes_bc=nx.current_flow_betweenness_centrality(G, normalized=True, weight=None, dtype='float', solver='full')\n",
    "    num_controller = np.sum(controller_nodes)\n",
    "    num_atomix = np.sum(atomix_nodes)\n",
    "    controller_list = np.nonzero(controller_nodes)[0].tolist()\n",
    "\n",
    "    if(num_controller == 0 or num_atomix ==0):\n",
    "        return math.inf\n",
    "\n",
    "    # find the nearest controller for each switch\n",
    "    controller_of = []\n",
    "    limit_num_switches_controlled=int(math.ceil(num_nodes/num_controller)) # balance the number of switches controllers can control \n",
    "    switches_bc_of_controller_ = dict.fromkeys((range(num_nodes)),0) # list of sum of betweenness centrality of switches for each controller\n",
    "    for s in range(num_nodes):\n",
    "        delay = math.inf\n",
    "        nearest_controller = None\n",
    "        controlled_switches=[]\n",
    "        for c in controller_list:\n",
    "            # Conditions: nearest controller (with the lowest delay) && the number of switches for each controller < limit_num_switches_controlled\n",
    "            if distance_matrix[s][c] < delay and controller_of.count(c) < limit_num_switches_controlled:\n",
    "                delay = distance_matrix[s][c]\n",
    "                nearest_controller = c\n",
    "                controlled_switches.append(s)\n",
    "        switches_bc_of_controller_[nearest_controller] += nodes_bc[str(s)]\n",
    "        controller_of.append(nearest_controller)\n",
    "    \n",
    "    # Simplify switches_bc_of_controller_ (only need value for calculating variance)\n",
    "    bc_array = []\n",
    "    for i in switches_bc_of_controller_.values():\n",
    "        bc_array.append(i)\n",
    "\n",
    "    # return variance value can show the degree of balance within all controllers\n",
    "    return np.var(bc_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c5160c",
   "metadata": {},
   "source": [
    "### Load Abvt results for all algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116921fb-1d91-4612-9876-69374c2df104",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res_bc_Abvt_agemoea.pkl','rb') as f_agemoea:\n",
    "    res_agemoea = pickle.load(f_agemoea)\n",
    "with open('res_bc_Abvt_agemoea2.pkl','rb') as f_agemoea2:\n",
    "    res_agemoea2 = pickle.load(f_agemoea2)\n",
    "with open('res_bc_Abvt_nsga2.pkl','rb') as f_nsga2:\n",
    "    res_nsga2 = pickle.load(f_nsga2)\n",
    "with open('res_bc_Abvt_nsga3.pkl','rb') as f_nsga3:\n",
    "    res_nsga3 = pickle.load(f_nsga3)\n",
    "with open('res_bc_Abvt_rnsga2.pkl','rb') as f_rnsga2:\n",
    "    res_rnsga2 = pickle.load(f_rnsga2)\n",
    "with open('res_bc_Abvt_rnsga3.pkl','rb') as f_rnsga3:\n",
    "    res_rnsga3 = pickle.load(f_rnsga3)\n",
    "with open('res_bc_Abvt_rvea.pkl','rb') as f_rvea:\n",
    "    res_rvea = pickle.load(f_rvea)\n",
    "with open('res_bc_Abvt_smsemoa.pkl','rb') as f_smsemoa:\n",
    "    res_smsemoa = pickle.load(f_smsemoa)\n",
    "with open('res_bc_Abvt_unsga3.pkl','rb') as f_unsga3:\n",
    "    res_unsga3 = pickle.load(f_unsga3)\n",
    "with open('res_bc_Abvt_ctaea.pkl','rb') as f_ctaea:\n",
    "    res_ctaea = pickle.load(f_ctaea)\n",
    "with open('res_bc_Abvt_dnsga2.pkl','rb') as f_dnsga2:\n",
    "    res_dnsga2 = pickle.load(f_dnsga2)\n",
    "with open('res_bc_Abvt_kgbdmoea.pkl','rb') as f_kgbdmoea:\n",
    "    res_kgbdmoea = pickle.load(f_kgbdmoea)\n",
    "with open('res_bc_Abvt_moead.pkl','rb') as f_moead:\n",
    "    res_moead = pickle.load(f_moead)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4970f1-b0dd-4149-b53c-6369435edc08",
   "metadata": {},
   "source": [
    "## Hypervolume\n",
    "1. Store values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc125b3-deb4-44d5-a5e2-8f3a4837e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abvt\n",
    "F_agemoea=res_agemoea.F\n",
    "F_agemoea2=res_agemoea2.F\n",
    "F_nsga2=res_nsga2.F\n",
    "F_nsga3=res_nsga3.F\n",
    "F_rnsga2=res_rnsga2.F\n",
    "F_rnsga3=res_rnsga3.F\n",
    "F_rvea=res_rvea.F\n",
    "F_smsemoa=res_smsemoa.F\n",
    "F_unsga3=res_unsga3.F\n",
    "F_ctaea=res_ctaea.F\n",
    "F_dnsga2=res_dnsga2.F\n",
    "F_kgbdmoea=res_kgbdmoea.F\n",
    "F_moead=res_moead.F\n",
    "\n",
    "ref_point = [181, 77, 3922.81875, 1.70537209]\n",
    "# agemoea\n",
    "# agemoea2\n",
    "# nsga2\n",
    "# nsga3\n",
    "# rnsga2\n",
    "# rnsga3\n",
    "# rvea\n",
    "# smsemoa\n",
    "# unsga3\n",
    "# ctaea\n",
    "# dnsga2\n",
    "# kgbdmoea\n",
    "# moead\n",
    "\n",
    "hist_F_agemoea = []\n",
    "hist_F_agemoea2 = []\n",
    "hist_F_nsga2 = []\n",
    "hist_F_nsga3 = []\n",
    "hist_F_rnsga2 = []\n",
    "hist_F_rnsga3 = []\n",
    "hist_F_rvea = []\n",
    "hist_F_smsemoa = []\n",
    "hist_F_unsga3 = []\n",
    "hist_F_ctaea = []\n",
    "hist_F_dnsga2 = []\n",
    "hist_F_kgbdmoea = []\n",
    "hist_F_moead = []\n",
    "\n",
    "for agemoea in res_agemoea.history:\n",
    "    opt_agemoea = agemoea.opt\n",
    "    feas_agemoea = np.where(opt_agemoea.get(\"feasible\"))[0]\n",
    "    hist_F_agemoea.append(opt_agemoea.get(\"F\")[feas_agemoea])\n",
    "for agemoea2 in res_agemoea2.history:\n",
    "    opt_agemoea2 = agemoea2.opt\n",
    "    feas_agemoea2 = np.where(opt_agemoea2.get(\"feasible\"))[0]\n",
    "    hist_F_agemoea2.append(opt_agemoea2.get(\"F\")[feas_agemoea2])\n",
    "for nsga2 in res_nsga2.history:\n",
    "    opt_nsga2 = nsga2.opt\n",
    "    feas_nsga2 = np.where(opt_nsga2.get(\"feasible\"))[0]\n",
    "    hist_F_nsga2.append(opt_nsga2.get(\"F\")[feas_nsga2])\n",
    "for nsga3 in res_nsga3.history:\n",
    "    opt_nsga3 = nsga3.opt\n",
    "    feas_nsga3 = np.where(opt_nsga3.get(\"feasible\"))[0]\n",
    "    hist_F_nsga3.append(opt_nsga3.get(\"F\")[feas_nsga3])\n",
    "for rnsga2 in res_rnsga2.history:\n",
    "    opt_rnsga2 = rnsga2.opt\n",
    "    feas_rnsga2 = np.where(opt_rnsga2.get(\"feasible\"))[0]\n",
    "    hist_F_rnsga2.append(opt_rnsga2.get(\"F\")[feas_rnsga2])\n",
    "for rnsga3 in res_rnsga3.history:\n",
    "    opt_rnsga3 = rnsga3.opt\n",
    "    feas_rnsga3 = np.where(opt_rnsga3.get(\"feasible\"))[0]\n",
    "    hist_F_rnsga3.append(opt_rnsga3.get(\"F\")[feas_rnsga3])\n",
    "for rvea in res_rvea.history:\n",
    "    opt_rvea = rvea.opt\n",
    "    feas_rvea = np.where(opt_rvea.get(\"feasible\"))[0]\n",
    "    hist_F_rvea.append(opt_rvea.get(\"F\")[feas_rvea])\n",
    "for smsemoa in res_smsemoa.history:\n",
    "    opt_smsemoa = smsemoa.opt\n",
    "    feas_smsemoa = np.where(opt_smsemoa.get(\"feasible\"))[0]\n",
    "    hist_F_smsemoa.append(opt_smsemoa.get(\"F\")[feas_smsemoa])\n",
    "for unsga3 in res_unsga3.history:\n",
    "    opt_unsga3 = unsga3.opt\n",
    "    feas_unsga3 = np.where(opt_unsga3.get(\"feasible\"))[0]\n",
    "    hist_F_unsga3.append(opt_unsga3.get(\"F\")[feas_unsga3])\n",
    "for ctaea in res_ctaea.history:\n",
    "    opt_ctaea = ctaea.opt\n",
    "    feas_ctaea = np.where(opt_ctaea.get(\"feasible\"))[0]\n",
    "    hist_F_ctaea.append(opt_ctaea.get(\"F\")[feas_ctaea])\n",
    "for dnsga2 in res_dnsga2.history:\n",
    "    opt_dnsga2 = dnsga2.opt\n",
    "    feas_dnsga2 = np.where(opt_dnsga2.get(\"feasible\"))[0]\n",
    "    hist_F_dnsga2.append(opt_dnsga2.get(\"F\")[feas_dnsga2])\n",
    "for kgbdmoea in res_kgbdmoea.history:\n",
    "    opt_kgbdmoea = kgbdmoea.opt\n",
    "    feas_kgbdmoea = np.where(opt_kgbdmoea.get(\"feasible\"))[0]\n",
    "    hist_F_kgbdmoea.append(opt_kgbdmoea.get(\"F\")[feas_kgbdmoea])\n",
    "for moead in res_moead.history:\n",
    "    opt_moead = moead.opt\n",
    "    feas_moead = np.where(opt_moead.get(\"feasible\"))[0]\n",
    "    hist_F_moead.append(opt_moead.get(\"F\")[feas_moead])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bc35ce",
   "metadata": {},
   "source": [
    "2. Calculate hypervolume for each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymoo.indicators.hv import Hypervolume\n",
    "\n",
    "metric = Hypervolume(ref_point= np.array(ref_point))\n",
    "\n",
    "hv_agemoea = [metric.do(_F_agemoea) for _F_agemoea in hist_F_agemoea]\n",
    "hv_agemoea2 = [metric.do(_F_agemoea2) for _F_agemoea2 in hist_F_agemoea2]\n",
    "hv_nsga2 = [metric.do(_F_nsga2) for _F_nsga2 in hist_F_nsga2]\n",
    "hv_nsga3 = [metric.do(_F_nsga3) for _F_nsga3 in hist_F_nsga3]\n",
    "hv_rnsga2 = [metric.do(_F_rnsga2) for _F_rnsga2 in hist_F_rnsga2]\n",
    "hv_rnsga3 = [metric.do(_F_rnsga3) for _F_rnsga3 in hist_F_rnsga3]\n",
    "hv_rvea = [metric.do(_F_rvea) for _F_rvea in hist_F_rvea]\n",
    "hv_smsemoa = [metric.do(_F_smsemoa) for _F_smsemoa in hist_F_smsemoa]\n",
    "hv_unsga3 = [metric.do(_F_unsga3) for _F_unsga3 in hist_F_unsga3]\n",
    "hv_ctaea = [metric.do(_F_ctaea) for _F_ctaea in hist_F_ctaea]\n",
    "hv_dnsga2 = [metric.do(_F_dnsga2) for _F_dnsga2 in hist_F_dnsga2]\n",
    "hv_kgbdmoea = [metric.do(_F_kgbdmoea) for _F_kgbdmoea in hist_F_kgbdmoea]\n",
    "hv_moead = [metric.do(_F_moead) for _F_moead in hist_F_moead]\n",
    "\n",
    "# hv_rnsga3 = [(hv_agemoea + hv_agemoea2 + hv_nsga2 + hv_nsga3 + hv_rnsga2 + hv_rnsga3 + hv_rvea + hv_smsemoa + hv_unsga3 + hv_ctaea + hv_dnsga2 + hv_kgbdmoea + hv_moead) / 13 for hv_agemoea, hv_agemoea2, hv_nsga2, hv_nsga3, hv_rnsga2, hv_rnsga3, hv_rvea, hv_smsemoa, hv_unsga3, hv_ctaea, hv_dnsga2, hv_kgbdmoea, hv_moead in zip(hv_agemoea, hv_agemoea2, hv_nsga2, hv_nsga3, hv_rnsga2, hv_rnsga3, hv_rvea, hv_smsemoa, hv_unsga3, hv_ctaea, hv_dnsga2, hv_kgbdmoea, hv_moead)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff19c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The hypervolumn for agemoea:')\n",
    "print(hv_agemoea)\n",
    "print('The hypervolumn for agemoea2:')\n",
    "print(hv_agemoea2)\n",
    "print('The hypervolumn for nsga2:')\n",
    "print(hv_nsga2)\n",
    "print('The hypervolumn for nsga3:')\n",
    "print(hv_nsga3)\n",
    "print('The hypervolumn for rnsga2:')\n",
    "print(hv_rnsga2)\n",
    "print('The hypervolumn for rnsga3:')\n",
    "print(hv_rnsga3)\n",
    "print('The hypervolumn for rvea:')\n",
    "print(hv_rvea)\n",
    "print('The hypervolumn for smsemoa:')\n",
    "print(hv_smsemoa)\n",
    "print('The hypervolumn for unsga3:')\n",
    "print(hv_unsga3)\n",
    "print('The hypervolumn for ctaea:')\n",
    "print(hv_ctaea)\n",
    "print('The hypervolumn for dnsga2:')\n",
    "print(hv_dnsga2)\n",
    "print('The hypervolumn for kgbdmoea:')\n",
    "print(hv_kgbdmoea)\n",
    "print('The hypervolumn for moead:')\n",
    "print(hv_moead)\n",
    "\n",
    "# Show all hv for each topo\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(list(range(1, len(hv_agemoea)+1)), hv_agemoea,  color='black', label='agemoea')\n",
    "plt.plot(list(range(1, len(hv_agemoea2)+1)), hv_agemoea2,  color='blue', label='agemoea2')\n",
    "plt.plot(list(range(1, len(hv_nsga2)+1)), hv_nsga2,  color='red', label='nsga2')\n",
    "plt.plot(list(range(1, len(hv_nsga3)+1)), hv_nsga3,  color='orange', label='nsga3')\n",
    "plt.plot(list(range(1, len(hv_rnsga2)+1)), hv_rnsga2,  color=(0, 0, 1, 0.5), label='rnsga2')\n",
    "plt.plot(list(range(1, len(hv_rnsga3)+1)), hv_rnsga3,  color='gray', label='rnsga3')\n",
    "plt.plot(list(range(1, len(hv_rvea)+1)), hv_rvea,  color='purple', label='rvea')\n",
    "plt.plot(list(range(1, len(hv_smsemoa)+1)), hv_smsemoa,  color='green', label='smsemoa')\n",
    "plt.plot(list(range(1, len(hv_unsga3)+1)), hv_unsga3,  color='#33FF57', label='unsga3')\n",
    "plt.plot(list(range(1, len(hv_ctaea)+1)), hv_ctaea,  color='brown', label='ctaea')\n",
    "plt.plot(list(range(1, len(hv_dnsga2)+1)), hv_dnsga2,  color='pink', label='dnsga2')\n",
    "plt.plot(list(range(1, len(hv_kgbdmoea)+1)), hv_kgbdmoea,  color='olive', label='kgbdmoea')\n",
    "plt.plot(list(range(1, len(hv_moead)+1)), hv_moead,  color='#FF5733', label='moead')\n",
    "plt.title(\"Convergence\")\n",
    "plt.xlabel(\"Generations\")\n",
    "plt.ylabel(\"Hypervolume\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20737ccc",
   "metadata": {},
   "source": [
    "2. Draw hypervolume for each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e79067e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "max_hv_agemoea = np.max(hv_agemoea, axis=0)\n",
    "max_hv_agemoea2 = np.max(hv_agemoea2, axis=0)\n",
    "max_hv_nsga2 = np.max(hv_nsga2, axis=0)\n",
    "max_hv_nsga3 = np.max(hv_nsga3, axis=0)\n",
    "max_hv_rnsga2 = np.max(hv_rnsga2, axis=0)\n",
    "max_hv_rnsga3 = np.max(hv_rnsga3, axis=0)\n",
    "max_hv_rvea = np.max(hv_rvea, axis=0)\n",
    "max_hv_smsemoa = np.max(hv_smsemoa, axis=0)\n",
    "max_hv_unsga3 = np.max(hv_unsga3, axis=0)\n",
    "max_hv_ctaea = np.max(hv_ctaea, axis=0)\n",
    "max_hv_dnsga2 = np.max(hv_dnsga2, axis=0)\n",
    "max_hv_kgbdmoea = np.max(hv_kgbdmoea, axis=0)\n",
    "max_hv_moead = np.max(hv_moead, axis=0)\n",
    "\n",
    "\n",
    "print('Maximum HV of AGEMOEA: ', + max_hv_agemoea)\n",
    "print('Maximum HV of AGEMOEA2: ', + max_hv_agemoea2)\n",
    "print('Maximum HV of NSGA2: ', + max_hv_nsga2)\n",
    "print('Maximum HV of NSGA3: ', + max_hv_nsga3)\n",
    "print('Maximum HV of RNSGA2: ', + max_hv_rnsga2)\n",
    "print('Maximum HV of RNSGA3: ', + max_hv_rnsga3)\n",
    "print('Maximum HV of RVEA: ', + max_hv_rvea)\n",
    "print('Maximum HV of SMSEMOA: ', + max_hv_smsemoa)\n",
    "print('Maximum HV of UNSGA3: ', + max_hv_unsga3)\n",
    "print('Maximum HV of CTAEA: ', + max_hv_ctaea)\n",
    "print('Maximum HV of DNSGA2: ', + max_hv_dnsga2)\n",
    "print('Maximum HV of KGBDMOEA: ', + max_hv_kgbdmoea)\n",
    "print('Maximum HV of MOEAD: ', + max_hv_moead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c173f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list = [84700536.64419575,\n",
    "# 84699583.53295648,\n",
    "# 84698873.36002482,\n",
    "# 84633155.23520696,\n",
    "# 84485344.90368119,\n",
    "# 83982909.13660179,\n",
    "# 84391189.9002668,\n",
    "# 84695027.95612651,\n",
    "# 84630457.38459831,\n",
    "# 84671679.72787946,\n",
    "# 86142329.83192006,\n",
    "# 86137966.71493277,\n",
    "# 82515082.41032088]\n",
    "# list_9 = [84700536.64419575,\n",
    "# 84699583.53295648,\n",
    "# 84698873.36002482,\n",
    "# 84633155.23520696,\n",
    "# 84485344.90368119,\n",
    "# 83982909.13660179,\n",
    "# 84695027.95612651,\n",
    "# 84630457.38459831,\n",
    "# 84671679.72787946]\n",
    "# # max_hv = np.max(list, axis=0)\n",
    "# max_hv = np.max(list_9, axis=0)\n",
    "# print(max_hv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
