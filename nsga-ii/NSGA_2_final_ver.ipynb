{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import itertools\n",
    "from itertools import chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\n",
    "#     \"half_pop_size\" : 50,\n",
    "#     \"problem_dim\" : 1,\n",
    "#     \"gene_min_val\" : 2,\n",
    "#     \"gene_max_val\" : 3,\n",
    "#     \"mutation_power_ratio\" : 1.05,\n",
    "# }\n",
    "\n",
    "# graph = {\n",
    "#     '1': {'3': 54},\n",
    "#     '2': {'3': 68},\n",
    "#     '3': {'1': 54, '2': 68}\n",
    "# }\n",
    "\n",
    "# print(graph)\n",
    "# convert_graph_to_array = [[int(source), int(target), weight] if target != '0' else [int(source), int(target), 0] for source, edges in graph.items() for target, weight in edges.items()]\n",
    "# print(convert_graph_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18']\n",
      "{'1': {'3': 82.99458278043693, '4': 38.0311153294585}, '2': {'6': 71.39569502299298, '7': 164.82129372183246, '8': 125.12889341007268}, '3': {'1': 82.99458278043693, '10': 44.40532335578192, '15': 60.085872515938526}, '4': {'1': 38.0311153294585}, '5': {'18': 40.94078297191167, '6': 73.00240078651599, '7': 39.63429170218247, '8': 82.63755970844781}, '6': {'2': 71.39569502299298, '5': 73.00240078651599}, '7': {'2': 164.82129372183246, '5': 39.63429170218247, '9': 82.95757267021366}, '8': {'2': 125.12889341007268, '5': 82.63755970844781}, '9': {'7': 82.95757267021366, '17': 128.55298324149916, '18': 69.60040685366947, '16': 80.63749756519596}, '10': {'3': 44.40532335578192, '18': 53.8990046198166, '14': 66.0212258943215, '16': 165.44426544490818}, '11': {'12': 124.27954969591543, '16': 93.02721253398369}, '12': {'11': 124.27954969591543, '18': 97.37414158154495, '13': 56.22293094713925, '16': 38.90792597867574}, '13': {'12': 56.22293094713925, '14': 34.37094579691975, '15': 50.643929335722085, '16': 94.00634375520872}, '14': {'10': 66.02122589432157, '13': 34.37094579691975, '15': 16.37608707101773}, '15': {'3': 60.085872515938526, '13': 50.643929335722085, '14': 16.376087071017736, '18': 5.745325757683184, '16': 134.60231940716625}, '16': {'9': 80.63749756519596, '10': 165.44426544490818, '11': 93.02721253398369, '12': 38.90792597867574, '13': 94.00634375520872, '15': 134.60231940716625, '17': 63.939794628835195, '18': 135.54764213855776}, '17': {'9': 128.55298324149916, '16': 63.939794628835195}, '18': {'5': 40.94078297191167, '9': 69.60040685366947, '10': 53.8990046198166, '12': 97.3741415815449, '15': 5.745325757683184, '16': 135.54764213855776}}\n",
      "[[1, 3, 82.99458278043693], [1, 4, 38.0311153294585], [2, 6, 71.39569502299298], [2, 7, 164.82129372183246], [2, 8, 125.12889341007268], [3, 1, 82.99458278043693], [3, 10, 44.40532335578192], [3, 15, 60.085872515938526], [4, 1, 38.0311153294585], [5, 18, 40.94078297191167], [5, 6, 73.00240078651599], [5, 7, 39.63429170218247], [5, 8, 82.63755970844781], [6, 2, 71.39569502299298], [6, 5, 73.00240078651599], [7, 2, 164.82129372183246], [7, 5, 39.63429170218247], [7, 9, 82.95757267021366], [8, 2, 125.12889341007268], [8, 5, 82.63755970844781], [9, 7, 82.95757267021366], [9, 17, 128.55298324149916], [9, 18, 69.60040685366947], [9, 16, 80.63749756519596], [10, 3, 44.40532335578192], [10, 18, 53.8990046198166], [10, 14, 66.0212258943215], [10, 16, 165.44426544490818], [11, 12, 124.27954969591543], [11, 16, 93.02721253398369], [12, 11, 124.27954969591543], [12, 18, 97.37414158154495], [12, 13, 56.22293094713925], [12, 16, 38.90792597867574], [13, 12, 56.22293094713925], [13, 14, 34.37094579691975], [13, 15, 50.643929335722085], [13, 16, 94.00634375520872], [14, 10, 66.02122589432157], [14, 13, 34.37094579691975], [14, 15, 16.37608707101773], [15, 3, 60.085872515938526], [15, 13, 50.643929335722085], [15, 14, 16.376087071017736], [15, 18, 5.745325757683184], [15, 16, 134.60231940716625], [16, 9, 80.63749756519596], [16, 10, 165.44426544490818], [16, 11, 93.02721253398369], [16, 12, 38.90792597867574], [16, 13, 94.00634375520872], [16, 15, 134.60231940716625], [16, 17, 63.939794628835195], [16, 18, 135.54764213855776], [17, 9, 128.55298324149916], [17, 16, 63.939794628835195], [18, 5, 40.94078297191167], [18, 9, 69.60040685366947], [18, 10, 53.8990046198166], [18, 12, 97.3741415815449], [18, 15, 5.745325757683184], [18, 16, 135.54764213855776]]\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"half_pop_size\" : 10,\n",
    "    \"problem_dim\" : 1,\n",
    "    \"gene_min_val\" : 2,\n",
    "    \"gene_max_val\" : 18,\n",
    "    \"mutation_power_ratio\" : 1.05,\n",
    "}\n",
    "\n",
    "# RioDeJaneiro = self.addSwitch( 's0' )\n",
    "# Paris = self.addSwitch( 's1' )\n",
    "# Miami = self.addSwitch( 's2' )\n",
    "# SaoPaulo = self.addSwitch( 's3' )\n",
    "# Amsterdam = self.addSwitch( 's4' )\n",
    "# Frankfurt = self.addSwitch( 's5' )\n",
    "# London = self.addSwitch( 's6' )\n",
    "# Brussels = self.addSwitch( 's7' )\n",
    "# NewYork = self.addSwitch( 's8' )\n",
    "# Atlanta = self.addSwitch( 's9' )\n",
    "# Seattle = self.addSwitch( 's10' )\n",
    "# SanJose/SanFrancisco = self.addSwitch( 's11' )\n",
    "# LosAngeles = self.addSwitch( 's12' )\n",
    "# Phoenix = self.addSwitch( 's13' )\n",
    "# Dallas = self.addSwitch( 's14' )\n",
    "# Chicago = self.addSwitch( 's15' )\n",
    "# Toronto = self.addSwitch( 's16' )\n",
    "# Ashburn = self.addSwitch( 's17' )\n",
    "\n",
    "RioDeJaneiro = '1' \n",
    "Paris = '2'\n",
    "Miami = '3' \n",
    "SaoPaulo = '4' \n",
    "Amsterdam = '5' \n",
    "Frankfurt = '6' \n",
    "London = '7' \n",
    "Brussels = '8' \n",
    "NewYork = '9' \n",
    "Atlanta = '10' \n",
    "Seattle = '11' \n",
    "SanJoseORSanFrancisco = '12' \n",
    "LosAngeles = '13' \n",
    "Phoenix =  '14' \n",
    "Dallas = '15' \n",
    "Chicago =  '16' \n",
    "Toronto = '17'\n",
    "Ashburn =  '18' \n",
    "switches_place = [RioDeJaneiro, Paris, Miami, SaoPaulo, Amsterdam, Frankfurt, London, Brussels, NewYork, Atlanta, Seattle, SanJoseORSanFrancisco, LosAngeles, Phoenix, Dallas, Chicago, Toronto, Ashburn]\n",
    "print(switches_place)\n",
    "\n",
    "graph = {\n",
    "    '1': {'3': 82.99458278043693, '4': 38.0311153294585 },\n",
    "    #  Miami = '82.99458278043693ms'\n",
    "    #  SaoPaulo ='38.0311153294585ms'\n",
    "    '2': {'6': 71.39569502299298, '7': 164.82129372183246, '8': 125.12889341007268},\n",
    "    #  Frankfurt ='71.39569502299298ms'\n",
    "    #  London ='164.82129372183246ms'\n",
    "    #  Brussels ='125.12889341007268ms'\n",
    "    '3': {'1': 82.99458278043693, '10': 44.40532335578192, '15': 60.085872515938526},\n",
    "    # RioDeJaneiro = '82.99458278043693ms'\n",
    "    # Atlanta ='44.40532335578192ms'\n",
    "    # Dallas ='60.085872515938526ms'\n",
    "    '4':{'1': 38.0311153294585},\n",
    "    # RioDeJaneiro ='38.0311153294585ms'\n",
    "    '5':{'18': 40.94078297191167, '6': 73.00240078651599, '7': 39.63429170218247, '8':82.63755970844781},\n",
    "    # Ashburn ='40.94078297191167ms'\n",
    "    # Frankfurt ='73.00240078651599ms'\n",
    "    # London ='39.63429170218247ms'\n",
    "    # Brussels ='82.63755970844781ms'\n",
    "    '6':{'2': 71.39569502299298, '5': 73.00240078651599},\n",
    "    # Paris ='71.39569502299298ms'\n",
    "    # Amsterdam ='73.00240078651599ms'\n",
    "    '7':{'2': 164.82129372183246, '5': 39.63429170218247, '9': 82.95757267021366},\n",
    "    # Paris ='164.82129372183246ms'\n",
    "    # Amsterdam ='39.63429170218247ms'\n",
    "    # NewYork ='82.95757267021366ms'\n",
    "    '8':{'2': 125.12889341007268, '5': 82.63755970844781},\n",
    "    # Paris ='125.12889341007268ms'\n",
    "    # Amsterdam ='82.63755970844781ms'\n",
    "    '9':{'7': 82.95757267021366, '17': 128.55298324149916, '18': 69.60040685366947, '16': 80.63749756519596},\n",
    "    # London ='82.95757267021366ms'\n",
    "    # Toronto ='128.55298324149916ms'\n",
    "    # Ashburn ='69.60040685366947ms'\n",
    "    # Chicago ='80.63749756519596ms'\n",
    "    '10':{'3': 44.40532335578192, '18': 53.8990046198166, '14': 66.0212258943215, '16': 165.44426544490818},\n",
    "    # Miami ='44.40532335578192ms'\n",
    "    # Ashburn ='53.8990046198166ms'\n",
    "    # Phoenix ='66.02122589432157ms'\n",
    "    # Chicago ='165.44426544490818ms'\n",
    "    '11':{'12': 124.27954969591543, '16': 93.02721253398369},\n",
    "    # SanJoseORSanFrancisco ='124.27954969591543ms'\n",
    "    # Chicago ='93.02721253398369ms'\n",
    "    '12':{'11': 124.27954969591543, '18': 97.37414158154495, '13': 56.22293094713925, '16': 38.90792597867574},\n",
    "    # Seattle ='124.27954969591543ms'\n",
    "    # Ashburn ='97.37414158154495ms'\n",
    "    #  LosAngeles ='56.22293094713925ms'\n",
    "    #  Chicago ='38.90792597867574ms'\n",
    "    '13':{'12': 56.22293094713925, '14': 34.37094579691975, '15': 50.643929335722085, '16': 94.00634375520872},\n",
    "    # SanJoseORSanFrancisco ='56.22293094713925ms'\n",
    "    # Phoenix ='34.37094579691975ms'\n",
    "    # Dallas ='50.643929335722085ms'\n",
    "    # Chicago ='94.00634375520872ms'\n",
    "    '14':{'10': 66.02122589432157, '13': 34.37094579691975, '15': 16.37608707101773},\n",
    "    # Atlanta ='66.02122589432157ms'\n",
    "    # LosAngeles ='34.37094579691975ms'\n",
    "    # Dallas ='16.376087071017736ms'\n",
    "    '15':{'3': 60.085872515938526, '13': 50.643929335722085, '14': 16.376087071017736, '18': 5.745325757683184, '16': 134.60231940716625},\n",
    "    # Miami ='60.085872515938526ms'\n",
    "    # LosAngeles ='50.643929335722085ms'\n",
    "    # Phoenix ='16.376087071017736ms'\n",
    "    # Ashburn ='5.745325757683184ms'\n",
    "    # Chicago ='134.60231940716625ms'\n",
    "    '16':{'9': 80.63749756519596, '10': 165.44426544490818, '11': 93.02721253398369, '12': 38.90792597867574, '13': 94.00634375520872, '15': 134.60231940716625, '17': 63.939794628835195, '18': 135.54764213855776},\n",
    "    # NewYork ='80.63749756519596ms'\n",
    "    # Atlanta ='165.44426544490818ms'\n",
    "    # Seattle ='93.02721253398369ms'\n",
    "    # SanJoseORSanFrancisco ='38.90792597867574ms'\n",
    "    # LosAngeles ='94.00634375520872ms'\n",
    "    # Dallas ='134.60231940716625ms'\n",
    "    # Toronto ='63.939794628835195ms'\n",
    "    # Ashburn ='135.54764213855776ms'\n",
    "    '17':{'9': 128.55298324149916, '16': 63.939794628835195},\n",
    "    # NewYork ='128.55298324149916ms'\n",
    "    # Chicago ='63.939794628835195ms'\n",
    "    '18':{'5': 40.94078297191167, '9': 69.60040685366947, '10': 53.8990046198166, '12': 97.3741415815449, '15': 5.745325757683184, '16': 135.54764213855776},\n",
    "    # Amsterdam ='40.94078297191167ms'\n",
    "    # NewYork ='69.60040685366947ms'\n",
    "    # Atlanta ='53.8990046198166ms'\n",
    "    # SanJoseORSanFrancisco ='97.37414158154495ms'\n",
    "    # Dallas ='5.745325757683184ms'\n",
    "    # Chicago ='135.54764213855776ms'\n",
    "}\n",
    "print(graph)\n",
    "convert_graph_to_array = [[int(source), int(target), weight] if target != '0' else [int(source), int(target), 0] for source, edges in graph.items() for target, weight in edges.items()]\n",
    "print(convert_graph_to_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dominates(fitnesses_1,fitnesses_2):\n",
    "    # fitnesses_1 is a array of objectives of solution 1 [objective1, objective2 ...]\n",
    "    larger_or_equal = fitnesses_1 >= fitnesses_2\n",
    "    larger = fitnesses_1 > fitnesses_2\n",
    "    if np.all(larger_or_equal) and np.any(larger):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "def dijkstra(graph, start, end):\n",
    "    distances = {node: float('inf') for node in graph}\n",
    "    distances[start] = 0\n",
    "    priority_queue = [(0, start)]\n",
    "\n",
    "    previous_nodes = {node: None for node in graph}\n",
    "\n",
    "    while priority_queue:\n",
    "        current_distance, current_node = heapq.heappop(priority_queue)\n",
    "\n",
    "        if current_distance > distances[current_node]:\n",
    "            continue\n",
    "\n",
    "        if current_node == end:\n",
    "            path = []\n",
    "            while current_node is not None:\n",
    "                path.append(current_node)\n",
    "                current_node = previous_nodes[current_node]\n",
    "            path.reverse()\n",
    "            return path\n",
    "\n",
    "        for neighbor, weight in graph[current_node].items():\n",
    "            distance = current_distance + weight\n",
    "\n",
    "            if distance < distances[neighbor]:\n",
    "                distances[neighbor] = distance\n",
    "                previous_nodes[neighbor] = current_node\n",
    "                heapq.heappush(priority_queue, (distance, neighbor))\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_possible_placement(x):\n",
    "\n",
    "    all_random_choose = x\n",
    "\n",
    "    switch_nodes = list(range(1,config.get('gene_max_val')+1))\n",
    "\n",
    "    onos_placement  = []\n",
    "    atomix_placement  = []\n",
    "    raw_all_combi_placement = []\n",
    "    all_combi_placement = []\n",
    "    final_all_combi_placement = []\n",
    "    final_all_combi_placement_a = []\n",
    "    \n",
    "    for x in range(len(all_random_choose)):\n",
    "        # print(x) # 0,1,...,9\n",
    "        onos_nodes = ['c{}'.format(item) for item in range(1,all_random_choose[x,0]+1)]\n",
    "        atomix_nodes = ['a{}'.format(item) for item in range(1,all_random_choose[x,1]+1)]\n",
    "\n",
    "        raw_onos_placement = [[onos, switch] for onos in onos_nodes for switch in switch_nodes if onos != switch]\n",
    "        raw_atomix_placement = [[atomix, switch] for atomix in atomix_nodes for switch in switch_nodes if atomix != switch]\n",
    "        \n",
    "        for combination in itertools.combinations(raw_onos_placement, len(onos_nodes)):\n",
    "            if len(set([item[0] for item in combination])) == len(onos_nodes) and len(set([item[1] for item in combination])) > len(onos_nodes)-1:\n",
    "                onos_placement.append(combination)\n",
    "\n",
    "        for combination in itertools.combinations(raw_atomix_placement, len(atomix_nodes)):\n",
    "            if len(set([item[0] for item in combination])) == len(atomix_nodes) and len(set([item[1] for item in combination])) > len(atomix_nodes)-1:\n",
    "                atomix_placement.append(combination)\n",
    "            \n",
    "        raw_all_combi_placement = [[onos, atomix] for onos in onos_placement for atomix in atomix_placement if onos != atomix]\n",
    "\n",
    "        all_combi_placement.append((x,raw_all_combi_placement))\n",
    "        # all_combi_placement.append((x,raw_all_combi_placement))\n",
    "\n",
    "        onos_placement  = []\n",
    "        atomix_placement  = []\n",
    "\n",
    "        # counter = 0\n",
    "        combined_list = []\n",
    "        raw_all_combi_placement = []\n",
    "        \n",
    "\n",
    "    for pop in all_combi_placement:\n",
    "        for each_placement in pop[1]:\n",
    "            for i in range(len(each_placement)):\n",
    "                combined_list.extend(each_placement[i])\n",
    "            final_all_combi_placement_a.append(combined_list)\n",
    "            combined_list = []\n",
    "        final_all_combi_placement.append((pop[0],final_all_combi_placement_a))\n",
    "        final_all_combi_placement_a = []\n",
    "\n",
    "    return final_all_combi_placement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_choose_a_placement_for_each_pop(final_all_combi_placement):\n",
    "    random_placement = []\n",
    "    pick_placement_array = []\n",
    "    for each_p in range(len(final_all_combi_placement)):\n",
    "        pick_placement = np.random.randint(len(final_all_combi_placement[0][1]))\n",
    "        random_placement.append((each_p, final_all_combi_placement[each_p][1][pick_placement]))\n",
    "        pick_placement_array.append(pick_placement)\n",
    "\n",
    "    return random_placement, pick_placement_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version#3\n",
    "def add_delay(fitnesses):\n",
    "    raw_delay = []\n",
    "    assign_delay = 0\n",
    "    delay = []\n",
    "    # result = []\n",
    "\n",
    "    # for placement_combi in onos_placement:\n",
    "    for ith, placement_combi in enumerate(fitnesses):\n",
    "\n",
    "        onos_nodes = [elem[0] for elem in placement_combi[1] if elem[0].startswith('c')]\n",
    "        atomix_nodes = [elem[0] for elem in placement_combi[1] if elem[0].startswith('a')]\n",
    "        switch_nodes = [elem for elem in range(1,config[\"gene_max_val\"]+1)]\n",
    "\n",
    "        # for ele in placement_combi[1]:  \n",
    "        onos_array = [elem for elem in placement_combi[1] if elem[0].startswith('c')]\n",
    "        atomix_array = [elem for elem in placement_combi[1] if elem[0].startswith('a')]\n",
    "\n",
    "        # switch to onos\n",
    "        for sTo_switch in switch_nodes:\n",
    "            for sTo_onos in onos_nodes:\n",
    "                start_sTo_switch = sTo_switch\n",
    "                end_sTo_onos = [item[1] for item in onos_array if item[0] == sTo_onos][0]\n",
    "                sTo_path = dijkstra(graph, str(start_sTo_switch), str(end_sTo_onos))\n",
    "\n",
    "                if len(sTo_path) == 1:\n",
    "                    raw_delay.append(('s{}'.format(sTo_switch), sTo_onos, 0))\n",
    "                else:\n",
    "                    for node_along_sTo_path in range(len(sTo_path)):\n",
    "                        slice_start_sTo = node_along_sTo_path\n",
    "                        slice_end_sTo = node_along_sTo_path + 2\n",
    "                        if slice_end_sTo > len(sTo_path):\n",
    "                            break\n",
    "                        else:\n",
    "                            pick_sTo_delay = [item[2] for item in convert_graph_to_array if [str(item[0]), str(item[1])] == sTo_path[slice_start_sTo:slice_end_sTo]]\n",
    "                            assign_delay += int(pick_sTo_delay[0])\n",
    "                    raw_delay.append(('s{}'.format(sTo_switch), sTo_onos, assign_delay))\n",
    "                    assign_delay = 0\n",
    "        \n",
    "        # onos to atomix\n",
    "        for oTa_onos in onos_nodes:\n",
    "            for oTa_atomix in atomix_nodes:\n",
    "                start_oTa_onos = [item[1] for item in onos_array if item[0] == oTa_onos][0]\n",
    "                end_oTa_atomix = [item[1] for item in atomix_array if item[0] == oTa_atomix][0]\n",
    "                oTa_path = dijkstra(graph, str(start_oTa_onos), str(end_oTa_atomix))\n",
    "\n",
    "                if len(oTa_path) == 1:\n",
    "                    raw_delay.append((oTa_onos, oTa_atomix, 0))\n",
    "                else:\n",
    "                    for node_along_oTa_path in range(len(oTa_path)):\n",
    "                        slice_start_oTa = node_along_oTa_path\n",
    "                        slice_end_oTa = node_along_oTa_path + 2\n",
    "                        if slice_end_oTa > len(oTa_path):\n",
    "                            break\n",
    "                        else:\n",
    "                            pick_oTa_delay = [item[2] for item in convert_graph_to_array if [str(item[0]), str(item[1])] == oTa_path[slice_start_oTa:slice_end_oTa]]\n",
    "                            assign_delay += int(pick_oTa_delay[0])\n",
    "                    raw_delay.append((oTa_onos, oTa_atomix, assign_delay))\n",
    "                    assign_delay = 0\n",
    "\n",
    "        # atomix to atomix\n",
    "        for aTa_start_atomix in atomix_nodes:\n",
    "            for aTa_end_atomix in atomix_nodes:\n",
    "                start_aTa_atomix = [item[1] for item in atomix_array if item[0] == aTa_start_atomix][0]\n",
    "                end_aTa_atomix = [item[1] for item in atomix_array if item[0] == aTa_end_atomix][0]\n",
    "                aTa_path = dijkstra(graph, str(start_aTa_atomix), str(end_aTa_atomix))\n",
    "\n",
    "                if len(aTa_path) == 1:\n",
    "                        # raw_delay.append(('a{}'.format(aTa_start_atomix), 'a{}'.format(aTa_end_atomix), 0))\n",
    "                        raw_delay.append((aTa_start_atomix, aTa_end_atomix, 0))\n",
    "                else:\n",
    "                    for node_along_aTa_path in range(len(aTa_path)):\n",
    "                        slice_start_aTa = node_along_aTa_path\n",
    "                        slice_end_aTa = node_along_aTa_path + 2\n",
    "                        if slice_end_aTa > len(aTa_path):\n",
    "                            break\n",
    "                        else:\n",
    "                            pick_aTa_delay = [item[2] for item in convert_graph_to_array if [str(item[0]), str(item[1])] == aTa_path[slice_start_aTa:slice_end_aTa]]\n",
    "                            assign_delay += int(pick_aTa_delay[0])\n",
    "                    # raw_delay.append(('a{}'.format(aTa_start_atomix), 'a{}'.format(aTa_end_atomix), assign_delay))\n",
    "                    raw_delay.append((aTa_start_atomix, aTa_end_atomix, assign_delay))        \n",
    "                    assign_delay = 0\n",
    "\n",
    "        delay.append((ith, raw_delay))\n",
    "        raw_delay = []\n",
    "    \n",
    "    return delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fst(all_delay):  \n",
    "    # convert_graph_to_array = [[1, 3, 54], [2, 3, 68], [3, 1, 54], [3, 2, 68]]\n",
    "    new_all_delay = []\n",
    "    for xth, each_delay in enumerate(all_delay):\n",
    "        # print(each_delay)\n",
    "\n",
    "        raw_delay_sTo = [elem for elem in each_delay[1] if elem[0].startswith('s')]\n",
    "        raw_delay_oTa = [elem for elem in each_delay[1] if elem[0].startswith('c')]\n",
    "        raw_delay_aTa = [elem for elem in each_delay[1] if elem[0].startswith('a')]\n",
    "\n",
    "        new_delay_sTo = []\n",
    "        for delay_sTo in raw_delay_sTo:\n",
    "            if len(new_delay_sTo) == 0:\n",
    "                new_delay_sTo.append(delay_sTo)\n",
    "            elif delay_sTo[0] == new_delay_sTo[-1][0]:\n",
    "                get_delay = delay_sTo[2]\n",
    "                old_delay = new_delay_sTo[-1][2]\n",
    "                if get_delay >= old_delay:\n",
    "                    min_delay = old_delay\n",
    "                else:\n",
    "                    new_delay_sTo.pop()\n",
    "                    new_delay_sTo.append(delay_sTo)\n",
    "            else:\n",
    "                new_delay_sTo.append(delay_sTo)\n",
    "\n",
    "        combi_all_delay = []\n",
    "\n",
    "        for sTo in new_delay_sTo:\n",
    "            combi_all_delay.append(sTo)\n",
    "\n",
    "        for oTa in raw_delay_oTa:\n",
    "            combi_all_delay.append(oTa)\n",
    "            \n",
    "        for aTa in raw_delay_aTa:\n",
    "            combi_all_delay.append(aTa)\n",
    "\n",
    "        new_all_delay.append((xth+1, combi_all_delay))\n",
    "    \n",
    "    final_delay = []\n",
    "    for yth, element_with_delay in enumerate(new_all_delay):\n",
    "\n",
    "        new_delay_sTo = [elem for elem in element_with_delay[1] if elem[0].startswith('s')]\n",
    "        new_delay_oTa = [elem for elem in element_with_delay[1] if elem[0].startswith('c')]\n",
    "        new_delay_aTa = [elem for elem in element_with_delay[1] if elem[0].startswith('a')]\n",
    "\n",
    "        switch_nodes = sorted(set([elem[0] for elem in element_with_delay[1] if elem[0].startswith('s')]))\n",
    "        onos_nodes = sorted(set([elem[0] for elem in element_with_delay[1] if elem[0].startswith('c')]))\n",
    "        atomix_nodes = sorted(set([elem[0] for elem in element_with_delay[1] if elem[0].startswith('a')]))\n",
    "        \n",
    "        # print(element_with_delay)\n",
    "\n",
    "\n",
    "        sTo_delay_amount = 0\n",
    "        oTa_delay_amount = 0\n",
    "        aTa_delay_amount = 0\n",
    "        total_delay = 0\n",
    "\n",
    "        # [('s1', 'c1', 0), ('s2', 'c2', 0), ('s3', 'c1', 54)]\n",
    "        # switch to onos delay\n",
    "        sum_sTo_delay = 0\n",
    "        for sTo_item in new_delay_sTo:\n",
    "            sum_sTo_delay += sTo_item[2]\n",
    "        sTo_delay_amount = 4*sum_sTo_delay\n",
    "        # print(sTo_delay_amount)\n",
    "        \n",
    "\n",
    "        # [('c1', 'a1', 0), ('c1', 'a2', 122), ('c1', 'a3', 54), ('c2', 'a1', 122), ('c2', 'a2', 0), ('c2', 'a3', 68)]\n",
    "        # onos to atomix delay\n",
    "        # delay of start node and end node\n",
    "        sum_oTa_delay_of_startAndEnd = 0\n",
    "        oTa_delay_amount_of_startAndEnd = 0\n",
    "\n",
    "        for oTa_item in new_delay_oTa:\n",
    "            sum_oTa_delay_of_startAndEnd += oTa_item[2]\n",
    "        oTa_delay_amount_of_startAndEnd = sum_oTa_delay_of_startAndEnd*2/len(atomix_nodes)\n",
    "\n",
    "        # delay of onos to atomix across middle node\n",
    "        path = dijkstra(graph, '1', '2') \n",
    "        # print(path) #['1', '3', '2']\n",
    "        \n",
    "        sum_oTa_delay_of_middle = 0\n",
    "        oTa_delay_amount_of_middle = 0\n",
    "\n",
    "        for middle_switch_index in range(1,len(path)-1):\n",
    "            master_onos_of_middle_switch = [master_onos[1] for master_onos in new_delay_sTo if master_onos[0][1]==path[middle_switch_index]]\n",
    "\n",
    "            # print(master_onos_of_middle_switch) # c1 or c2 or c3...\n",
    "            for oTa_item in new_delay_oTa:\n",
    "                if oTa_item[0] == master_onos_of_middle_switch:\n",
    "                    sum_oTa_delay_of_middle += oTa_item[2]\n",
    "        oTa_delay_amount_of_middle = sum_oTa_delay_of_middle/len(atomix_nodes)\n",
    "        oTa_delay_amount = oTa_delay_amount_of_startAndEnd + oTa_delay_amount_of_middle\n",
    "        # print(oTa_delay_amount)\n",
    "        \n",
    "        \n",
    "        # [('a1', 'a1', 0), ('a1', 'a2', 122), ('a1', 'a3', 54), ('a2', 'a1', 122), ('a2', 'a2', 0), ('a2', 'a3', 68), ('a3', 'a1', 54), ('a3', 'a2', 68), ('a3', 'a3', 0)]\n",
    "        # atomix to atomix delay\n",
    "        aTa_delay_amount = 0\n",
    "        sum_aTa_delay = 0\n",
    "        atomix_node_array = []\n",
    "\n",
    "\n",
    "        # sum_aTa_delay = 0\n",
    "        for atomix_start_node in atomix_nodes:\n",
    "            # print(atomix_start_node) # a1, a2, a3, ...\n",
    "            atomix_node_array = [start_atomix for start_atomix in new_delay_aTa if start_atomix[0]==atomix_start_node]\n",
    "            # print(atomix_node_array) # [('a1', 'a1', 0), ('a1', 'a2', 122), ('a1', 'a3', 54)]\n",
    "            atomix_delay_array = [atomix_delay[2] for atomix_delay in atomix_node_array if atomix_delay[2]>0]\n",
    "            # print(atomix_delay_array) # [122, 54]\n",
    "            min_delay = min(atomix_delay_array)\n",
    "            # print(min_delay) # 54\n",
    "            sum_aTa_delay += min_delay\n",
    "\n",
    "        # print(sum_aTa_delay) #176\n",
    "        aTa_delay_amount = (2*sum_aTa_delay)/len(atomix_nodes)\n",
    "        # print(aTa_delay_amount)\n",
    "            \n",
    "        total_delay = sTo_delay_amount + oTa_delay_amount + aTa_delay_amount\n",
    "        # print(total_delay)\n",
    "\n",
    "        final_delay.append((yth, element_with_delay[1], len(switch_nodes), len(onos_nodes), len(atomix_nodes), total_delay))\n",
    "        \n",
    "        # print()\n",
    "    return final_delay\n",
    "\n",
    "\n",
    "# pop = np.random.randint(config[\"gene_min_val\"],config[\"gene_max_val\"]+1,(2*config[\"half_pop_size\"], 2))\n",
    "# final_all_combi_placement = all_possible_placement(pop)\n",
    "# random_placement, pick_placement_array = random_choose_a_placement_for_each_pop(final_all_combi_placement)\n",
    "# delay = add_delay(random_placement)\n",
    "# for aaa in delay:\n",
    "#     print(aaa)\n",
    "# final_delay = calculate_fst(delay)\n",
    "# # fitnesses = fitness_func(final_delay)\n",
    "\n",
    "\n",
    "# final_fitnesses = calculate_fst(test_dalay)\n",
    "# ((1, [('s1', 'c1', 0), ('s2', 'c2', 0), ('s3', 'c1', 54), ('c1', 'a1', 0), ('c1', 'a2', 122), ('c1', 'a3', 54), ('c2', 'a1', 122), ('c2', 'a2', 0), ('c2', 'a3', 68), ('a1', 'a1', 0), ('a1', 'a2', 122), ('a1', 'a3', 54), ('a2', 'a1', 122), ('a2', 'a2', 0), ('a2', 'a3', 68), ('a3', 'a1', 54), ('a3', 'a2', 68), ('a3', 'a3', 0)]), 636.0000000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 -> topo id\n",
    "# 1 -> placement with delay\n",
    "# 2 -> the number of switch nodes\n",
    "# 3 -> the number of onos nodes\n",
    "# 4 -> the number of atomix nodes\n",
    "# 5 -> total delay\n",
    "def fitness_func(x):\n",
    "    sample = []\n",
    "\n",
    "    for id, fit in enumerate(x):\n",
    "        num_onos = fit[3] # the number of onos nodes\n",
    "        num_atomix = fit[4] # the number of atomix nodes\n",
    "        total_delay = fit[5] # total delay\n",
    "        delay_unit = 10\n",
    "        objective_1 = total_delay + (num_onos*delay_unit)**2\n",
    "        objective_2 = total_delay + (num_atomix*delay_unit)**2\n",
    "        \n",
    "        sample.append([objective_1,objective_2])\n",
    "\n",
    "\n",
    "    all_final_delay_fitnesses = np.array(sample)\n",
    "    return all_final_delay_fitnesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-29400\n"
     ]
    }
   ],
   "source": [
    "total_delay = 3000\n",
    "num_atomix =18\n",
    "delay_unit = 10\n",
    "print(total_delay - (num_atomix*delay_unit)**2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non dominated sorting: fast approach (worst case complexity O(M N^2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pareto_fronts(fitnesses):\n",
    "    \n",
    "    # Calculate dominated set for each individual\n",
    "    domination_sets = []\n",
    "    domination_counts = []\n",
    "    for fitnesses_1 in fitnesses:\n",
    "        current_dimination_set = set()\n",
    "        domination_counts.append(0)\n",
    "        for i,fitnesses_2 in enumerate(fitnesses):\n",
    "            if dominates(fitnesses_1,fitnesses_2):\n",
    "                current_dimination_set.add(i)\n",
    "            elif dominates(fitnesses_2,fitnesses_1):\n",
    "                domination_counts[-1] += 1\n",
    "\n",
    "        domination_sets.append(current_dimination_set)\n",
    "\n",
    "    domination_counts = np.array(domination_counts)\n",
    "    fronts = []\n",
    "    while True:\n",
    "        current_front = np.where(domination_counts==0)[0]\n",
    "        if len(current_front) == 0:\n",
    "            #print(\"Done\")\n",
    "            break\n",
    "        #print(\"Front: \",current_front)\n",
    "        fronts.append(current_front)\n",
    "\n",
    "        for individual in current_front:\n",
    "            domination_counts[individual] = -1 # this individual is already accounted for, make it -1 so  ==0 will not find it anymore\n",
    "            dominated_by_current_set = domination_sets[individual]\n",
    "            for dominated_by_current in dominated_by_current_set:\n",
    "                domination_counts[dominated_by_current] -= 1\n",
    "            \n",
    "    return fronts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diversity Preservation (crowding metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An important aspect of multiobjective optimization is that we explore the different possible tradoffs.\n",
    "# To do this effectively we need to encourage a diversity in the population.\n",
    "# NSGA-II uses a crowding metric to do this.\n",
    "# The crowding metric is based on how close the neerest neighbors in the same front are for each objective. \n",
    "\n",
    "\n",
    "def calculate_crowding_metrics(fitnesses,fronts):\n",
    "    num_objectives = fitnesses.shape[1]\n",
    "    num_individuals = fitnesses.shape[0]\n",
    "    \n",
    "    # Normalise each objectives, so they are in the range [0,1]\n",
    "    # This is necessary, so each objective's contribution have the same magnitude to the crowding metric.\n",
    "    normalized_fitnesses = np.zeros_like(fitnesses)\n",
    "    for objective_i in range(num_objectives):\n",
    "        \n",
    "        min_val = np.min(fitnesses[:,objective_i])\n",
    "        max_val = np.max(fitnesses[:,objective_i])\n",
    "        val_range = max_val - min_val\n",
    "        normalized_fitnesses[:,objective_i] = (fitnesses[:,objective_i] - min_val) / val_range\n",
    "    \n",
    "    fitnesses = normalized_fitnesses\n",
    "    crowding_metrics = np.zeros(num_individuals)\n",
    "\n",
    "    for front in fronts:\n",
    "        for objective_i in range(num_objectives):\n",
    "            \n",
    "            sorted_front = sorted(front,key = lambda x : fitnesses[x,objective_i])\n",
    "            \n",
    "            crowding_metrics[sorted_front[0]] = np.inf\n",
    "            crowding_metrics[sorted_front[-1]] = np.inf\n",
    "            if len(sorted_front) > 2:\n",
    "                for i in range(1,len(sorted_front)-1):\n",
    "                    crowding_metrics[sorted_front[i]] += fitnesses[sorted_front[i+1],objective_i] - fitnesses[sorted_front[i-1],objective_i]\n",
    "\n",
    "    return  crowding_metrics\n",
    "\n",
    "\n",
    "# print(np.inf + 0.14327485380116958 - 0.11793372319688103)\n",
    "# pop = np.random.randint(config[\"gene_min_val\"],config[\"gene_max_val\"]+1,(2*config[\"half_pop_size\"], 2))\n",
    "# final_all_combi_placement = all_possible_placement(pop)\n",
    "# random_placement, pick_placement_array = random_choose_a_placement_for_each_pop(final_all_combi_placement)\n",
    "# delay = add_delay(random_placement)\n",
    "# final_delay = calculate_fst(delay)\n",
    "# fitnesses = fitness_func(final_delay)\n",
    "\n",
    "# fronts = calculate_pareto_fronts(fitnesses)\n",
    "# crowding = calculate_crowding_metrics(fitnesses,fronts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting with domination and crowding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sorting the population we need both the nondomination rank and the crowding metric\n",
    "# We always consider the nondomination rank first, but in a tie we use the crowding metric\n",
    "\n",
    "# helper function\n",
    "def fronts_to_nondomination_rank(fronts):\n",
    "    nondomination_rank_dict = {}\n",
    "    for i,front in enumerate(fronts):\n",
    "        for x in front:   \n",
    "            nondomination_rank_dict[x] = i\n",
    "    return nondomination_rank_dict\n",
    "        \n",
    "\n",
    "def nondominated_sort(nondomination_rank_dict,crowding):\n",
    "    \n",
    "    num_individuals = len(crowding)\n",
    "    indicies = list(range(num_individuals))\n",
    "\n",
    "    def nondominated_compare(a,b):\n",
    "        # returns 1 if a dominates b, or if they equal, but a is less crowded\n",
    "        # return -1 if b dominates a, or if they equal, but b is less crowded\n",
    "        # returns 0 if they are equal in every sense\n",
    "        \n",
    "        \n",
    "        if nondomination_rank_dict[a] > nondomination_rank_dict[b]:  # domination rank, smaller better\n",
    "            return -1\n",
    "        elif nondomination_rank_dict[a] < nondomination_rank_dict[b]:\n",
    "            return 1\n",
    "        else:\n",
    "            if crowding[a] < crowding[b]:   # crowding metrics, larger better\n",
    "                return -1\n",
    "            elif crowding[a] > crowding[b]:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "    non_domiated_sorted_indicies = sorted(indicies,key = functools.cmp_to_key(nondominated_compare),reverse=True) # decreasing order, the best is the first\n",
    "    return non_domiated_sorted_indicies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all togeather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some generic GA functions\n",
    "def touranment_selection(num_parents,num_offspring):\n",
    "    offspring_parents = []\n",
    "    for _ in range(num_offspring):\n",
    "        contestants = np.random.randint(0,num_parents,2) # generate 2 random numbers, take the smaller (parent list is already sorted, smaller index, better)\n",
    "        winner = np.min(contestants)\n",
    "        offspring_parents.append(winner)\n",
    "    \n",
    "    return offspring_parents\n",
    "\n",
    "# simple mutation\n",
    "def get_mutated_copy(parent,min_val,max_val,mutation_power_ratio):\n",
    "    mutation_power = (max_val - min_val) * mutation_power_ratio\n",
    "    offspring = parent.copy()\n",
    "    offspring += np.random.randint(0,mutation_power,size = offspring.shape)\n",
    "    \n",
    "    offspring = np.clip(offspring,min_val,max_val)\n",
    "    return offspring\n",
    "\n",
    "\n",
    "def NSGA2_create_next_generation(pop,fitnesses,config):\n",
    "    \n",
    "    # algorithm and task parameters\n",
    "    half_pop_size = config[\"half_pop_size\"]\n",
    "    problem_dim = config[\"problem_dim\"]\n",
    "    gene_min_val = config[\"gene_min_val\"]\n",
    "    gene_max_val = config[\"gene_max_val\"]\n",
    "    mutation_power_ratio = config[\"mutation_power_ratio\"]\n",
    "\n",
    "    # calculate the pareto fronts and crowding metrics\n",
    "    fronts = calculate_pareto_fronts(fitnesses)\n",
    "    # print('fronts')\n",
    "    # print(fronts)\n",
    "    # print()\n",
    "\n",
    "    nondomination_rank_dict = fronts_to_nondomination_rank(fronts)\n",
    "    # print('nondomination_rank_dict')\n",
    "    # print(nondomination_rank_dict)\n",
    "    # print()\n",
    "\n",
    "    crowding = calculate_crowding_metrics(fitnesses,fronts)\n",
    "    # print('crowding')\n",
    "    # print(crowding)\n",
    "    # print()\n",
    "    \n",
    "    # Sort the population\n",
    "    non_domiated_sorted_indicies = nondominated_sort(nondomination_rank_dict,crowding)\n",
    "    # print('non_domiated_sorted_indicies')\n",
    "    # print(non_domiated_sorted_indicies)\n",
    "    # print()\n",
    "    \n",
    "    # The better half of the population survives to the next generation and have a chance to reproduce\n",
    "    # The rest of the population is discarded\n",
    "    surviving_individuals = pop[non_domiated_sorted_indicies[:half_pop_size]]\n",
    "    # print('surviving_individuals')\n",
    "    # print(surviving_individuals)\n",
    "    # print()\n",
    "\n",
    "    reproducing_individual_indicies = touranment_selection(num_parents=half_pop_size,num_offspring=half_pop_size)\n",
    "    # print('reproducing_individual_indicies')\n",
    "    # print(reproducing_individual_indicies)\n",
    "    # print()\n",
    "\n",
    "    offsprings = np.array([get_mutated_copy(surviving_individuals[i],gene_min_val,gene_max_val,mutation_power_ratio) for i in reproducing_individual_indicies])\n",
    "    # print('offsprings')\n",
    "    # print(offsprings)\n",
    "    # print()\n",
    "    \n",
    "    new_pop = np.concatenate([surviving_individuals,offsprings])  # concatenate the 2 lists\n",
    "    # print('new_pop')\n",
    "    # print(new_pop)\n",
    "    # print()\n",
    "    return new_pop, non_domiated_sorted_indicies[:half_pop_size]\n",
    "\n",
    "\n",
    "# pop = np.random.randint(config[\"gene_min_val\"],config[\"gene_max_val\"]+1,(2*config[\"half_pop_size\"], 2))\n",
    "# final_all_combi_placement = all_possible_placement(pop)\n",
    "# random_placement, pick_placement_array = random_choose_a_placement_for_each_pop(final_all_combi_placement)\n",
    "# delay = add_delay(random_placement)\n",
    "# final_delay = calculate_fst(delay)\n",
    "# fitnesses = fitness_func(final_delay)\n",
    "\n",
    "# pop = NSGA2_create_next_generation(pop,fitnesses,config) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving the toy problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = np.random.randint(config[\"gene_min_val\"],config[\"gene_max_val\"]+1,(2*config[\"half_pop_size\"], 2))\n",
    "# print(pop)\n",
    "# print()\n",
    "\n",
    "all_place = []\n",
    "final_optimal_placement = []\n",
    "\n",
    "for generation in range(50):\n",
    "    \n",
    "    # evaluate pop\n",
    "    final_all_combi_placement = all_possible_placement(pop)\n",
    "    random_placement, pick_placement_array = random_choose_a_placement_for_each_pop(final_all_combi_placement)\n",
    "    delay = add_delay(random_placement)\n",
    "    final_delay = calculate_fst(delay)\n",
    "    fitnesses = fitness_func(final_delay)\n",
    "    \n",
    "    # transition to next generation\n",
    "    pop, last_generation_optimal_placement = NSGA2_create_next_generation(pop,fitnesses,config)\n",
    "\n",
    "    # all_place.append(final_all_combi_placement)\n",
    "\n",
    "# print(final_all_combi_placement == all_place[1])\n",
    "\n",
    "for each_optimal_index in last_generation_optimal_placement:\n",
    "    final_optimal_placement.append(final_all_combi_placement[each_optimal_index])\n",
    "# print(len(final_optimal_placement))\n",
    "# for aaaaaaaaaa in final_optimal_placement:\n",
    "#     print(aaaaaaaaaa)\n",
    "print(final_all_combi_placement)\n",
    "\n",
    "\n",
    "all_pop = np.random.randint(config[\"gene_min_val\"],config[\"gene_max_val\"]+1,(100, 2))\n",
    "# print(len(all_pop))\n",
    "final_all_combi_placement = all_possible_placement(all_pop)\n",
    "random_placement, pick_placement_array = random_choose_a_placement_for_each_pop(final_all_combi_placement)\n",
    "delay = add_delay(random_placement)\n",
    "final_delay = calculate_fst(delay)\n",
    "all_solutions_fitnesses = fitness_func(final_delay)\n",
    "plt.plot(all_solutions_fitnesses[:,0],all_solutions_fitnesses[:,1],\".\")\n",
    "# print(len(fitnesses))\n",
    "plt.plot(fitnesses[:config[\"half_pop_size\"],0],fitnesses[:config[\"half_pop_size\"],1],\".\",color=\"red\")\n",
    "plt.xlabel(\"ONOS\")\n",
    "plt.ylabel(\"Atomix\")\n",
    "\n",
    "# # # first\n",
    "# a = [3, 12, 78, 90, 15, 19, 20, 23, 58, 60, 66, 67, 74, 75, 86, 8, 24, 97, 98, 95, 27, 9, 10, 11, 13, 14, 16, 25, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52, 54, 70, 72, 77, 79, 83, 88, 89, 91, 92, 96, 5, 42, 55, 94, 0, 99, 6, 18, 21, 33, 46, 57, 59, 61, 62, 63, 64, 68, 69, 73, 82, 85, 87, 93, 4, 81, 71, 1, 26, 65, 84, 7, 22, 56, 80, 2, 76, 17, 53]\n",
    "\n",
    "# # # last\n",
    "# b = [3, 12, 78, 90, 15, 19, 20, 23, 58, 60, 66, 67, 74, 75, 86, 8, 24, 97, 98, 95, 27, 9, 10, 11, 13, 14, 16, 25, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 47, 48, 49, 50, 51, 52]\n",
    "\n",
    "# # # print_last\n",
    "# c = a[:50]\n",
    "\n",
    "# print(a == b)\n",
    "# print(a == c)\n",
    "# print(b == c) T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
